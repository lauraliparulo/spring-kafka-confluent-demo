spring.application.name=spring-kafka-demo

# Kafka
spring.kafka.properties.sasl.mechanism=PLAIN
spring.kafka.bootstrap-servers=pkc-921jm.us-east-2.aws.confluent.cloud:9092
spring.kafka.properties.sasl.jaas.config=org.apache.kafka.common.security.plain.PlainLoginModule required username='QQINBSGMMY4M2QXK' password='Qn8CYFWEI/hVbIkaybDAT08vhvaBR/dWpi10gW6J8dGGpVan8WJ0h2ULGNe2OQpP';
spring.kafka.properties.security.protocol=SASL_SSL


# Required connection configs for Kafka producer, consumer, and admin
# bootstrap.servers=pkc-921jm.us-east-2.aws.confluent.cloud:9092
# security.protocol=SASL_SSL
# sasl.jaas.config=org.apache.kafka.common.security.plain.PlainLoginModule required username='QQINBSGMMY4M2QXK' password='Qn8CYFWEI/hVbIkaybDAT08vhvaBR/dWpi10gW6J8dGGpVan8WJ0h2ULGNe2OQpP';
# sasl.mechanism=PLAIN
# Required for correctness in Apache Kafka clients prior to 2.6
# client.dns.lookup=use_all_dns_ips

# Best practice for higher availability in Apache Kafka clients prior to 3.0
#session.timeout.ms=45000

# Best practice for Kafka producer to prevent data loss
#acks=all


#you won't be able to produce to Confluent Cloud without schema Registry!
#basic.auth.credentials.source=USER_INFO
#schema.registry.url=https://psrc-8vyvr.eu-central-1.aws.confluent.cloud
#basic.auth.user.info=AJJH5WDEAXUMZOCD:HNbQnmFDLu/WB4b2o7JULmjmC27c9kRPbXCmNv8kaIIlbsxY5eyCFPe14tuoLNBE

# producer
spring.kafka.producer.key-serializer=org.apache.kafka.common.serialization.IntegerSerializer
spring.kafka.producer.value-serializer=org.apache.kafka.common.serialization.StringSerializer
spring.kafka.producer.client-id=spring-boot-producer

#consumer
#spring.kafka.consumer.key-deserializer=org.apache.kafka.common.serialization.StringDeserializer
#spring.kafka.consumer.value-deserializer=org.apache.kafka.common.serialization.LongDeserializer

#stream
# spring.kafka.streams.replication-factor=3
# spring.kafka.streams.application-id=spring-boot-streams